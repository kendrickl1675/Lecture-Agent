import torch
import torchvision
import huggingface_hub
import transformers
from langchain_huggingface import HuggingFaceEmbeddings

print("="*40)
print("ğŸ” æœ€ç»ˆç¯å¢ƒæ ¸æŸ¥")
print("="*40)

print(f"âœ… PyTorch ç‰ˆæœ¬: {torch.__version__}")
print(f"âœ… Vision ç‰ˆæœ¬:  {torchvision.__version__}")
print(f"âœ… CUDA å¯ç”¨æ€§:  {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"   - æ˜¾å¡: {torch.cuda.get_device_name(0)}")

print(f"âœ… Hub ç‰ˆæœ¬:     {huggingface_hub.__version__} (é¢„æœŸ: >=1.3.5)")
print(f"âœ… Transformers: {transformers.__version__}")

print("\n[æµ‹è¯•] å°è¯•åŠ è½½ Embeddings æ¨¡å‹...")
try:
    # ä½¿ç”¨ä¸€ä¸ªå°æ¨¡å‹å¿«é€ŸéªŒè¯æ¥å£å…¼å®¹æ€§
    emb = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        model_kwargs={'device': 'cuda'} # ç¡®ä¿èƒ½è°ƒç”¨æ˜¾å¡
    )
    vec = emb.embed_query("FinTech Test")
    print(f"ğŸ‰ æˆåŠŸ! ç”Ÿæˆå‘é‡ç»´åº¦: {len(vec)}")
except Exception as e:
    print(f"âŒ å¤±è´¥: {e}")