import time
import os
import re
import logging
from agent_core import LectureAgentCore

# --- åŸºç¡€é…ç½® ---
OBSIDIAN_PATH = r"./test_notes"  # âš ï¸ Betaæµ‹è¯•æ—¶è¯·ç¡®è®¤æ­¤è·¯å¾„æŒ‡å‘ä½ çš„å…‹éš†åº“
LOG_FILE = "agent_runtime.log"

# --- è§¦å‘æ ‡ç­¾é…ç½® ---
START_TAG = "<ai>"
END_TAG = "</ai>"
# DOTALL æ¨¡å¼ç¡®ä¿ . èƒ½åŒ¹é…æ¢è¡Œç¬¦ï¼Œæ•è·å¤šè¡Œå†…å®¹
PATTERN = re.compile(f"{re.escape(START_TAG)}(.*?){re.escape(END_TAG)}", re.DOTALL)

# --- ç»“æ„ä¿æŠ¤æ­£åˆ™ ---
# åŒ¹é…å›¾ç‰‡ ![[...]]
REGEX_IMG = re.compile(r'(!\[\[.*?\]\])')
# åŒ¹é…åŒå‘é“¾æ¥ [[...]] (æ’é™¤å‰é¢æœ‰!çš„æƒ…å†µ)
REGEX_LINK = re.compile(r'(?<!\!)(\[\[.*?\]\])')
# åŒ¹é… Callout æ ‡é¢˜ (ä¾‹å¦‚ > [!NOTE] Title)
REGEX_CALLOUT_HEADER = re.compile(r'^>\s*\[!.*?\](.*)$', re.MULTILINE)

# ==========================================
# âœ… æ ¸å¿ƒ: æ—¥å¿—ç³»ç»Ÿé…ç½® (å«é™å™ª)
# ==========================================
logging.basicConfig(
    filename=LOG_FILE,
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%H:%M:%S',
    encoding='utf-8'
)

# ğŸ”‡ é™éŸ³åˆ—è¡¨ï¼šå±è”½ HTTP è¯·æ±‚å’Œ Google SDK çš„å†…éƒ¨å•°å—¦æ—¥å¿—
silence_list = [
    "urllib3", "requests", "sentence_transformers", "huggingface_hub", "chromadb",
    "httpcore", "httpx",
    "google.generativeai",
    "google.ai.generativelanguage",
    "google.auth",
    "langchain_google_genai",
    "google_genai",  # ğŸ‘ˆ é’ˆå¯¹ AFC æ—¥å¿—çš„å…³é”®å±è”½
]

for logger_name in silence_list:
    logging.getLogger(logger_name).setLevel(logging.WARNING)

# æ§åˆ¶å°åŒæ­¥è¾“å‡º (æ–¹ä¾¿è‚‰çœ¼ç¡®è®¤è¿è¡ŒçŠ¶æ€)
console = logging.StreamHandler()
console.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(message)s')
console.setFormatter(formatter)
logging.getLogger('').addHandler(console)


class ContentProtector:
    """
    å†…å®¹ä¿æŠ¤å™¨ï¼šåœ¨å‘ç»™ LLM ä¹‹å‰ï¼Œå°†å›¾ç‰‡å’Œé“¾æ¥æ›¿æ¢ä¸ºå ä½ç¬¦ï¼Œ
    å¤„ç†å®Œåå†è¿˜åŸï¼Œé˜²æ­¢ LLM ä¿®æ”¹æˆ–åˆ é™¤å…³é”®é“¾æ¥ã€‚
    """

    def __init__(self):
        self.map = {}
        self.counter = 0

    def protect(self, text):
        self.map = {}
        self.counter = 0

        def replace_match(match, prefix):
            token = f"__{prefix}_{self.counter}__"
            self.map[token] = match.group(0)  # å­˜å‚¨åŸå§‹å†…å®¹
            self.counter += 1
            return token

        # å…ˆä¿æŠ¤å›¾ç‰‡ï¼Œå†ä¿æŠ¤é“¾æ¥
        text = REGEX_IMG.sub(lambda m: replace_match(m, "IMG"), text)
        text = REGEX_LINK.sub(lambda m: replace_match(m, "LINK"), text)
        return text

    def restore(self, text):
        # å°†å ä½ç¬¦è¿˜åŸä¸ºåŸå§‹å†…å®¹
        for token, original in self.map.items():
            text = text.replace(token, original)
        return text


def scan_and_process(agent):
    # é€’å½’æ‰«æç›®å½•ä¸‹æ‰€æœ‰ .md æ–‡ä»¶
    for root, dirs, files in os.walk(OBSIDIAN_PATH):
        for file in files:
            if file.endswith(".md"):
                file_path = os.path.join(root, file)
                process_segment(agent, file_path)


def process_segment(agent, file_path):
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()

        # å¿«é€Ÿæ£€æŸ¥ï¼šå¦‚æœæ–‡ä»¶é‡Œæ²¡æ ‡ç­¾ï¼Œç›´æ¥è·³è¿‡ï¼ŒèŠ‚çœèµ„æº
        if START_TAG not in content:
            return

        matches = list(PATTERN.finditer(content))
        if not matches:
            return

        logging.info(f"ğŸ“‚ Detected {len(matches)} segments in: {os.path.basename(file_path)}")

        new_content = content

        # âš ï¸ å…³é”®ï¼šå€’åºå¤„ç† (Reversed)
        # å¿…é¡»ä»æ–‡ä»¶æœ«å°¾å¼€å§‹æ›¿æ¢ï¼Œå¦åˆ™å‰é¢çš„æ›¿æ¢ä¼šæ”¹å˜å­—ç¬¦ä¸²é•¿åº¦ï¼Œå¯¼è‡´åç»­ç´¢å¼•å¤±æ•ˆ
        for match in reversed(matches):
            raw_segment = match.group(1).strip()

            # --- Step 1: ç»“æ„è¯†åˆ« (Callout vs æ™®é€šæ–‡æœ¬) ---
            is_callout = False
            callout_header = ""
            processing_text = raw_segment

            header_match = REGEX_CALLOUT_HEADER.match(raw_segment)

            if header_match:
                is_callout = True
                raw_header = raw_segment.split('\n')[0].strip()
                # è§„èŒƒåŒ– Callout æ ¼å¼ (ç¡®ä¿ > åæœ‰ç©ºæ ¼)
                if not raw_header.startswith("> "):
                    callout_header = raw_header.replace(">", "> ", 1)
                else:
                    callout_header = raw_header

                # æå–æ­£æ–‡ (å»é™¤æ¯ä¸€è¡Œå¼€å¤´çš„å¼•ç”¨ç¬¦ >)
                lines = raw_segment.split('\n')[1:]
                body_lines = [re.sub(r'^>\s?', '', line) for line in lines]
                processing_text = "\n".join(body_lines).strip()
                logging.info(f"  ğŸ”¹ Callout identified: {callout_header}")

            elif raw_segment.strip().startswith(">"):
                # å¤„ç†æ™®é€šå¼•ç”¨å—
                is_callout = True
                callout_header = ">"
                lines = raw_segment.split('\n')
                body_lines = [re.sub(r'^>\s?', '', line) for line in lines]
                processing_text = "\n".join(body_lines).strip()

            # --- Step 2: å†…å®¹ä¿æŠ¤ (åŠ å¯†) ---
            protector = ContentProtector()
            masked_text = protector.protect(processing_text)

            # --- Step 3: Agent å¤„ç† (è°ƒç”¨ LLM) ---
            processed_text = agent.generate_note(masked_text)

            # --- Step 4: è¿˜åŸä¸é‡ç»„ (è§£å¯† & æ ¼å¼åŒ–) ---
            if processed_text and "SKIP_PROCESSING" not in processed_text:
                # 4.1 è¿˜åŸå›¾ç‰‡å’Œé“¾æ¥
                restored_text = protector.restore(processed_text)
                final_replacement = ""

                if is_callout:
                    # 4.2 æ™ºèƒ½æ‹†åˆ†ï¼šå°† Term Analysis ç§»å‡º Callout
                    split_marker = None
                    # å…¼å®¹å¸¦ emoji å’Œä¸å¸¦ emoji çš„æ ‡é¢˜
                    if "### Key Term Analysis" in restored_text:
                        split_marker = "### Key Term Analysis"
                    elif "### ğŸ†Key Term Analysis" in restored_text:
                        split_marker = "### ğŸ†Key Term Analysis"

                    if split_marker:
                        parts = restored_text.split(split_marker)
                        academic_body = parts[0].strip()
                        term_analysis = split_marker + parts[1]  # æ‹¼æ¥å›å»
                    else:
                        academic_body = restored_text
                        term_analysis = ""

                    # 4.3 é‡å»ºå¼•ç”¨å— (åªç»™å­¦æœ¯æ­£æ–‡åŠ  >)
                    reconstructed_body = "\n".join([f"> {line}" for line in academic_body.split('\n')])

                    # 4.4 æœ€ç»ˆæ‹¼æ¥ï¼šHeader + å¼•ç”¨æ­£æ–‡ + å¤–éƒ¨çš„ Term Analysis
                    final_replacement = f"{callout_header}\n{reconstructed_body}\n\n{term_analysis}\n"
                else:
                    final_replacement = f"{restored_text}\n"

                # 4.5 æ›¿æ¢åŸæ–‡ (åŒ…å«é”€æ¯ <ai> æ ‡ç­¾)
                start_idx, end_idx = match.span()
                new_content = new_content[:start_idx] + final_replacement + new_content[end_idx:]
                logging.info("  âœ… Segment updated successfully")
            else:
                logging.info("  â­ï¸  Agent skipped processing")

        # å†™å…¥æ–‡ä»¶
        if new_content != content:
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(new_content)
            logging.info(f"ğŸ’¾ File saved: {os.path.basename(file_path)}")

    except Exception as e:
        logging.error(f"âŒ Error processing {file_path}: {e}")


def main():
    print("==================================================")
    print("   ğŸ‘ï¸ Lecture Note Daemon (Gemini 3 Preview)       ")
    print("==================================================")
    logging.info("Watcher started.")

    try:
        agent = LectureAgentCore()
        logging.info("Agent initialized.")
    except Exception as e:
        logging.critical(f"Failed to initialize Agent: {e}")
        return

    try:
        while True:
            scan_and_process(agent)
            time.sleep(2)
    except KeyboardInterrupt:
        logging.info("Watcher stopped.")


if __name__ == "__main__":
    main()