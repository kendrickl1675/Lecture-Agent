import torch
from faster_whisper import WhisperModel
import time

def check_environment():
    print("="*30)
    print("ç¯å¢ƒç¡¬ä»¶è‡ªæ£€ç¨‹åº")
    print("="*30)

    # 1. æ£€æŸ¥ PyTorch æ˜¯å¦è¯†åˆ«åˆ° CUDA
    if torch.cuda.is_available():
        device_name = torch.cuda.get_device_name(0)
        print(f"âœ… CUDA å°±ç»ª! æ˜¾å¡å‹å·: {device_name}")
        
        # ç®€å•æ˜¾å­˜æµ‹è¯•
        vram = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"âœ… æ˜¾å­˜æ€»é‡: {vram:.2f} GB (è¶³å¤Ÿè¿è¡Œ RAG + Whisper)")
    else:
        print("âŒ è­¦å‘Š: æœªæ£€æµ‹åˆ° GPUï¼Œå°†ä½¿ç”¨ CPU (é€Ÿåº¦ä¼šå¾ˆæ…¢)")
        return

    # 2. æ£€æŸ¥ Faster-Whisper åŠ è½½ (æ¨¡æ‹Ÿæ„ŸçŸ¥å±‚)
    print("\n[æµ‹è¯•] åŠ è½½ Whisper æ¨¡å‹ (è‡³æ˜¾å¡)...")
    try:
        start = time.time()
        # ä½¿ç”¨ tiny æ¨¡å‹è¿›è¡Œå¿«é€Ÿå†’çƒŸæµ‹è¯•
        model = WhisperModel("tiny", device="cuda", compute_type="float16")
        print(f"âœ… Whisper æ¨¡å‹åŠ è½½æˆåŠŸ! è€—æ—¶: {time.time() - start:.2f}s")
    except Exception as e:
        print(f"âŒ Whisper åŠ è½½å¤±è´¥: {e}")

    # 3. æ£€æŸ¥å‘é‡åº“ä¾èµ–
    try:
        from chromadb.utils import embedding_functions
        print("âœ… ChromaDB ä¾èµ–åŠ è½½æ­£å¸¸")
    except ImportError:
        print("âŒ ChromaDB åŠ è½½å¤±è´¥")

    print("\nğŸ‰ ç¯å¢ƒé…ç½®å®Œæˆï¼Œéšæ—¶å¯ä»¥å¼€å§‹å¼€å‘ï¼")

if __name__ == "__main__":
    check_environment()